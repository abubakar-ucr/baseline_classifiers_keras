{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout, Activation\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "from bs4 import BeautifulSoup\n",
    "import plotly.graph_objs as go\n",
    "#import plotly.plotly as py\n",
    "#import cufflinks\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import plotly.figure_factory as ff\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "from plotly.offline import iplot\n",
    "#cufflinks.go_offline()\n",
    "#cufflinks.set_config_file(world_readable=True, theme='pearl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data_sgd/train.tsv', header=None, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>sounds good, i want to buy tickets.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__3</td>\n",
       "      <td>please search a hotel for me there</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__4</td>\n",
       "      <td>nothing. just relax.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__5</td>\n",
       "      <td>shall i book a table here?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__6</td>\n",
       "      <td>no, not now.i need to check my account balance?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0                                                1\n",
       "0  __label__1              sounds good, i want to buy tickets.\n",
       "1  __label__3               please search a hotel for me there\n",
       "2  __label__4                             nothing. just relax.\n",
       "3  __label__5                       shall i book a table here?\n",
       "4  __label__6  no, not now.i need to check my account balance?"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__23</td>\n",
       "      <td>sounds good. can you find me a rental car ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__26</td>\n",
       "      <td>i need to check weather on the 5th of march.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__24</td>\n",
       "      <td>cool. schedule a visit.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__14</td>\n",
       "      <td>i would like to get a cab going there.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>would you like some tickets?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0                                                  1\n",
       "0  __label__23  sounds good. can you find me a rental car ther...\n",
       "1  __label__26       i need to check weather on the 5th of march.\n",
       "2  __label__24                            cool. schedule a visit.\n",
       "3  __label__14             i would like to get a cab going there.\n",
       "4   __label__1                       would you like some tickets?"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('data_sgd/test.tsv', header=None, sep=\"\\t\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4476 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 50000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 80#250\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 64\n",
    "\n",
    "\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(df1[1].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (47022, 80)\n"
     ]
    }
   ],
   "source": [
    "X1 = tokenizer.texts_to_sequences(df1[1].values)\n",
    "X1 = pad_sequences(X1, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (47022, 21)\n"
     ]
    }
   ],
   "source": [
    "Y1 = pd.get_dummies(df1[0]).values\n",
    "print('Shape of label tensor:', Y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (9838, 80)\n"
     ]
    }
   ],
   "source": [
    "X2 = tokenizer.texts_to_sequences(df2[1].values)\n",
    "X2 = pad_sequences(X2, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (9838, 21)\n"
     ]
    }
   ],
   "source": [
    "Y2 = pd.get_dummies(df2[0]).values\n",
    "print('Shape of label tensor:', Y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47022, 80) (47022, 21)\n",
      "(9838, 80) (9838, 21)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = X1,X2, Y1,Y2\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 80, 100)           5000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 80, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 78, 250)           75250     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                16064     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 21)                1365      \n",
      "=================================================================\n",
      "Total params: 5,092,679\n",
      "Trainable params: 5,092,679\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# we start off with an efficient embedding layer which maps\n",
    "# our vocab indices into embedding_dims dimensions\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X1.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "\n",
    "# we add a Convolution1D, which will learn filters\n",
    "# word group filters of size filter_length:\n",
    "\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "# we use max pooling:\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "model.add(Dense(HIDDEN_DIM))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a softmax:\n",
    "model.add(Dense(Y_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc',f1_m,precision_m, recall_m]) # metrics=['accuracy']\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 42319 samples, validate on 4703 samples\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:184: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "42319/42319 [==============================] - 20s 464us/step - loss: 0.8061 - acc: 0.7699 - f1_m: 0.7448 - precision_m: 0.8697 - recall_m: 0.6878 - val_loss: 0.3627 - val_acc: 0.8803 - val_f1_m: 0.8830 - val_precision_m: 0.9077 - val_recall_m: 0.8599\n",
      "Epoch 2/5\n",
      "42319/42319 [==============================] - 18s 421us/step - loss: 0.3249 - acc: 0.8927 - f1_m: 0.8935 - precision_m: 0.9180 - recall_m: 0.8706 - val_loss: 0.3202 - val_acc: 0.8924 - val_f1_m: 0.8954 - val_precision_m: 0.9220 - val_recall_m: 0.8707\n",
      "Epoch 3/5\n",
      "42319/42319 [==============================] - 18s 437us/step - loss: 0.2726 - acc: 0.9056 - f1_m: 0.9062 - precision_m: 0.9244 - recall_m: 0.8889 - val_loss: 0.3046 - val_acc: 0.8909 - val_f1_m: 0.8935 - val_precision_m: 0.9152 - val_recall_m: 0.8731\n",
      "Epoch 4/5\n",
      "42319/42319 [==============================] - 18s 423us/step - loss: 0.2444 - acc: 0.9102 - f1_m: 0.9105 - precision_m: 0.9270 - recall_m: 0.8948 - val_loss: 0.2889 - val_acc: 0.8922 - val_f1_m: 0.8939 - val_precision_m: 0.9084 - val_recall_m: 0.8801\n",
      "Epoch 5/5\n",
      "42319/42319 [==============================] - 18s 426us/step - loss: 0.2221 - acc: 0.9152 - f1_m: 0.9158 - precision_m: 0.9304 - recall_m: 0.9020 - val_loss: 0.2946 - val_acc: 0.8879 - val_f1_m: 0.8915 - val_precision_m: 0.9096 - val_recall_m: 0.8743\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9838/9838 [==============================] - 1s 79us/step\n",
      "Test set\n",
      "  Loss: 0.280\n",
      "  Accuracy: 0.901\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28009236134887106, 0.9006911973614934, 0.9072543589364563, 0.9232265153268557, 0.8923561699653597]\n"
     ]
    }
   ],
   "source": [
    "#loss, accuracy, f1_score, precision, recall\n",
    "print(accr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9838/9838 [==============================] - 1s 63us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8297    0.8342    0.8320       549\n",
      "           1     0.9348    0.9436    0.9392       319\n",
      "           2     0.9293    0.9500    0.9396       180\n",
      "           3     0.9207    0.9889    0.9536       270\n",
      "           4     0.9268    0.9694    0.9476       196\n",
      "           5     0.8041    0.8610    0.8316       367\n",
      "           6     0.8563    0.5200    0.6471       275\n",
      "           7     0.9769    0.8048    0.8825       210\n",
      "           8     0.9737    0.8916    0.9308       415\n",
      "           9     0.9193    0.9367    0.9279       158\n",
      "          10     0.7906    0.9012    0.8423       243\n",
      "          11     0.9260    0.9468    0.9363       357\n",
      "          12     0.7637    0.7658    0.7648       363\n",
      "          13     0.8061    0.9653    0.8785       577\n",
      "          14     0.8410    0.7405    0.7876       393\n",
      "          15     1.0000    0.9671    0.9833       213\n",
      "          16     0.9608    0.9367    0.9486      3380\n",
      "          17     0.7157    0.9338    0.8103       302\n",
      "          18     0.9655    0.9524    0.9589       294\n",
      "          19     0.9937    0.9781    0.9858       320\n",
      "          20     0.8504    0.8709    0.8605       457\n",
      "\n",
      "    accuracy                         0.9007      9838\n",
      "   macro avg     0.8898    0.8885    0.8852      9838\n",
      "weighted avg     0.9046    0.9007    0.9000      9838\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test, batch_size=64, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "print(classification_report(np.argmax(Y_test, axis=1), y_pred_bool, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
